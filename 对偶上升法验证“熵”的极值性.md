### 对偶上升法验证“熵”的极值性

#### 基本介绍

看到信息论的信息熵，是刻画样本不确定程度的，样本出现概率越接近，不确定性越高

信息熵：
$$
S(p_1,p_2,\cdots,p_n)=-K\sum^n_{i=1}p_ilog_2p_i
$$
其中有一个极值性：

所有样本等几率出现的情况下，熵达到最大值：
$$
S(p_1,p_2,\cdots,p_n)\leq S(\frac{1}{n},\cdots,\frac{1}{n})=log_2n
$$
#编写代码时用的都是ln函数，意思是一样的。

想证明一下这个性质，但由于学的不等式啊多元微积分啊什么的全忘光了，干脆写个代码算就完了

主要验证思想是求解优化问题：
$$
\begin{align}
\min_p:p^Tln(p) \\
s.t.\sum^n_{i=1}p_i&=1 \tag{1} \\
p_i&\leq1 \tag{2} \\
-p_i&\leq0 \tag{3}
\end{align}
$$
通过对偶上升法来优化，约束条件写成：
$$
Ap\leq b\\
A=
\left[
\begin{matrix}
1 & 1 & \cdots & 1 \\ \hline
1 & 0 & \cdots & 0 \\
0 & 1 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 1 \\ \hline
-1 & 0 & \cdots & 0 \\
0 & -1 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & -1
\end{matrix}
\right], 
b = 
\left[
\begin{matrix}
1 \\ \hline
1 \\ 
1 \\ 
\vdots \\ 
1 \\ \hline 
0 \\
0 \\
\vdots \\
0
\end{matrix}
\right]
$$
拉格朗日松弛函数：
$$
LR(p,u)=p^Tln(p)+u^T(Ap-b) \\
$$

拉格朗日乘子$ u\in \mathbb{R}^{2n+1×1}:u_{i\neq1}\geq 0 $

对偶上升法：
$$
\begin{align}
&p^{k+1}=\arg\min_xLR(p,u^k) \\
&u^{k+1}=u^k+a^k(Ax^{k+1})
\end{align}
$$

#### 代码备注

p为样本概率向量，每个分量代表一个样本出现的概率

n为样本数量，是可调参数，直接在程序里改即可

u为拉格朗日乘子，初始化为全0，每更新一次后需要确保其对应分量的正负号

p的argmin也用梯度下降法来求，a1为p梯度下降的系数，a2为u梯度上升的系数

梯度下降（上升）的终止条件为下降前后参数p(或u)的变化小于d

d控制最终结果的精度

输出指标：

随机初始化的init_p（$ \mathbb{R}^{n×1} $）

对偶上升结束后的p（$ \mathbb{R}^{n×1} $）

熵值entropy（$ \mathbb{R}^+ $）

熵值与理论值ln(n)的相对误差err_rel（%）

#### 运行结果

d = 0.0001，n = 20

![image-20220808151738735](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20220808151738735.png)

![image-20220808152143662](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20220808152143662.png)

d = 0.0001，n = 50

![image-20220808152541141](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20220808152541141.png)

![image-20220808152611891](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20220808152611891.png)

在样本数量n不同和p初始值不同的情况下，算法最终收敛到$ p_i=\frac{1}{n} $，得到的熵值也与理论值十分接近（其实理论值应该不用验算，也就是直接按定义式算的）

因此极值性得到验证
